{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a> 0.0 - Instalando Pacotes </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalando pacotes\n",
    "# %pip install sklearn\n",
    "# %pip install os\n",
    "# %pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a> 0.1 - Importando Bibliotecas e Funções auxiliares </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas para leitura dos dados e criação de gráficos\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# configurando pandas para mostrar todas as linhas e colunas\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "# configurando pandas para não mostrar notação científica para números\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a> 1.0 - Conhecendo os dados </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler os dados do banco.\n",
    "df_clientes = pd.read_csv('data\\Base_CadastroClientes_analise.csv', sep=';')\n",
    "\n",
    "# Mapear status - variável target para o modelo\n",
    "df_clientes['status'] = df_clientes['diasAtraso'].apply( lambda x: 0 if x == 0 else 1  )\n",
    "\n",
    "df_clientes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quais são os dados em sua totalidade, como estão formatados.\n",
    "df_clientes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando os tipos\n",
    "df_clientes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a> 1.1 - Transformações iniciais </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada linha é um cliente, portanto vamos verificar se isso é verdade?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes['id'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos transformar id em indice do dataframe\n",
    "df_clientes = df_clientes.set_index('id').sort_values(by= 'id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos transforma varíaveis com data em formato datetime\n",
    "df_clientes['dataNascimento'] = pd.to_datetime(df_clientes['dataNascimento'], format = '%d/%m/%Y')\n",
    "df_clientes['dataCadastro'] = pd.to_datetime(df_clientes['dataCadastro'], format = '%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a> 1.2 - Começando com estatística descritiva </a>\n",
    "\n",
    "Conhecer bem as medidas estatísticas, de tendência central, dispersão, separatrizes, distribuições, é essencial para conhecermos melhor os dados em que estamos trabalhando. Qual a distribuição de tempo de relacionamento? Da valor do contrato? Da renda mensal? A base está desbalanceada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mudando o padrão de quartis para decis. linspace divide em espaços iguais um intervalo de números (0 a 1 com 11 intervalos)\n",
    "df_clientes.describe(percentiles=np.linspace(0, 1, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos inferir que os dados em rendaMensal, diasAtraso, valorContrato estão de algum modo corrompidos. Estão apresentando dados de Ano, ao invés dos dados requisitados. As váriaveis de Range parecem sem mais interessantes para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a distribuição de tempo de relacionamento (meses na empresa)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize = (15,8))\n",
    "\n",
    "sns.histplot(data=df_clientes, x='range_tempoRelacionamento' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a distribuição do cidadeRendaPercapita\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize = (15,8))\n",
    "\n",
    "sns.histplot(data=df_clientes, x='range_cidadeRendaPercapita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a distribuição da estadoRendaPercapita\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize = (15,8))\n",
    "\n",
    "sns.histplot(data=df_clientes, x='range_estadoRendaPercapita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a distribuição da estadoRendaPercapita\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize = (15,8))\n",
    "\n",
    "sns.histplot(data=df_clientes, x='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shape_Atraso = len(df_clientes.loc[df_clientes['range_diasAtraso'] == 'NO PRAZO']), len(df_clientes.loc[df_clientes['range_diasAtraso'] != 'NO PRAZO'])\n",
    "print('Temos um total de {} clientes dentro do prazo para pagamento dos débitos, e um total de {} clientes em atraso '.format(Shape_Atraso[0],Shape_Atraso[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a> 2.0. - Limpeza e Codificação de Variáveis Categóricas </a>\n",
    "\n",
    "Lembrando que os modelos de machine learning não sabem o que são categorias em sua maioria, devemos, portanto, codificar as variáveis de sexo, parceiro(a), dependentes, tipo de cobrança e todos os tipos de serviço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_clientes.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira análise é de verificar dados nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clientes.loc[:,:].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando dados nulos\n",
    "df_clientes = df_clientes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clientes.loc[:,:].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar quantas classes possuem as variáveis categóricas para saber como codificar cada uma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes._get_numeric_data().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_categoricas = [coluna for coluna in df_clientes.columns if coluna not in df_clientes._get_numeric_data().columns]\n",
    "colunas_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna_categorica in colunas_categoricas:\n",
    "    display(df_clientes[coluna_categorica].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a> Codificando variáveis binárias </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear sexo\n",
    "df_clientes['sexo'] = df_clientes['sexo'].map({'Feminino': 1, 'Masculino': 0})\n",
    "# Será que funcionou?\n",
    "display(df_clientes['sexo'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remover duplicadas\n",
    "df_clientes = df_clientes.drop_duplicates(subset=['cpf'], keep='first')\n",
    "df_clientes = df_clientes.drop_duplicates(subset=['email'], keep='first')\n",
    "\n",
    "#Remover variáveis categoricas com muitas entradas ou com informações duplicadas\n",
    "df_clientes = df_clientes.drop(['cep', 'cidade','dataNascimento','dataCadastro',\n",
    "                                'profissao','empresa','veiculo','nome','estado',\n",
    "                                'rendaMensal', 'valorContrato', 'endereco', \n",
    "                                'diasAtraso','longitude', 'latitude', 'telefone',\n",
    "                                'email', 'cpf', 'tipoSanguineo','altura','peso','idade',\n",
    "                                'estadoRendaPercapita','cidadeRendaPercapita','tempoRelacionamento',\n",
    "                                'range_diasAtraso', 'uf'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear variáveis com Range\n",
    "df_clientes['range_valorContrato'] = df_clientes['range_valorContrato'].apply( lambda x: 1 if x == '1 - DE R$ 10.000 A R$ 20.000' else\n",
    "                                                                      2 if x == '2 - DE R$ 20.001 A R$ 40.000' else\n",
    "                                                                      3 if x == '3 - DE R$ 40.001 A R$ 70.000' else\n",
    "                                                                      4 if x == '4 - DE R$ 70.001 A R$ 90.000' else\n",
    "                                                                      5 if x == '5 - DE R$ 90.001 A 100.000 ' else\n",
    "                                                                      6 if x == '6 - ACIMA DE R$ 100.000' else 'Nan' )\n",
    "\n",
    "                                                    \n",
    "df_clientes['range_idade'] = df_clientes['range_idade'].apply( lambda x: 1 if x == '1 - De 18 a 25 Anos' else\n",
    "                                                            2 if x == '2 - De 26 a 40 Anos' else\n",
    "                                                            3 if x == '3 - De 41 a 55 Anos' else\n",
    "                                                            4 if x == '4 - De 56 A 70 Anos' else\n",
    "                                                            5 if x == '5 - De 71 A 80 Anos' else\n",
    "                                                            6 if x == '6 - Acima de 80 Anos' else 'Nan' )    \n",
    "\n",
    "df_clientes['range_estadoRendaPercapita'] = df_clientes['range_estadoRendaPercapita'].apply( lambda x: 1 if x == '1 - De R$ 500 A R$ 800' else\n",
    "                                                            2 if x == '2 - De R$ 801 A R$ 1.000' else\n",
    "                                                            3 if x == '3 - DE R$ 1.001 A R$ 1.200' else\n",
    "                                                            4 if x == '4 - DE R$ 1.201 A R$ 1.500' else\n",
    "                                                            5 if x == '5 - DE R$ 1.501 A R$ 1.800' else\n",
    "                                                            6 if x == '6 - ACIMA DE R$ 1.801' else 'Nan' ) \n",
    "\n",
    "df_clientes['range_rendaMensal'] = df_clientes['range_rendaMensal'].apply( lambda x: 1 if x == '1 - DE R$ 1.500 A R$ 2.000' else\n",
    "                                                            2 if x == '2 - DE R$ 2.001 A R$ 4.000' else\n",
    "                                                            3 if x == '3 - DE R$ 4.001 A R$ 6.000' else\n",
    "                                                            4 if x == '4 - DE R$ 6.001 A R$ 8.000' else\n",
    "                                                            5 if x == '5 - DE R$ 8.001 A R$ 9.000' else\n",
    "                                                            6 if x == '6 - ACIMA DE R$ 9.000' else 'Nan' )\n",
    "\n",
    "df_clientes['range_tempoRelacionamento'] = df_clientes['range_tempoRelacionamento'].apply( lambda x: 1 if x == '1 - DE 1 A 3 ANOS' else\n",
    "                                                                              2 if x == '2 - DE 4 A 10 ANOS' else\n",
    "                                                                              3 if x == '3 - DE 10 A 20 ANOS' else\n",
    "                                                                              4 if x == '4 - DE 21 A 25 ANOS' else\n",
    "                                                                              5 if x == '5 - DE 26 A 30 ANOS' else\n",
    "                                                                              6 if x == 'ACIMA DE 30 ANOS' else 'Nan' )  \n",
    "\n",
    "df_clientes['range_cidadeRendaPercapita'] = df_clientes['range_cidadeRendaPercapita'].apply( lambda x: 1 if x == '1 - De R$ 500 A R$ 800' else\n",
    "                                                                                          2 if x == '2 - De R$ 801 A R$ 1.000' else\n",
    "                                                                                          3 if x == '3 - DE R$ 1.001 A R$ 1.200' else\n",
    "                                                                                          4 if x == '4 - DE R$ 1.201 A R$ 1.500' else\n",
    "                                                                                          5 if x == '5 - DE R$ 1.501 A R$ 1.800' else\n",
    "                                                                                          6 if x == '6 - ACIMA DE R$ 1.801'else 'Nan' )\n",
    "colunas_categoricas = [coluna for coluna in df_clientes.columns if coluna not in df_clientes._get_numeric_data().columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna_categorica in colunas_categoricas:\n",
    "    display(df_clientes[coluna_categorica].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clientes.drop([ 'status'], axis=1) # tirando a variável dependente\n",
    "y = df_clientes[['status']] # extraindo a variável dependente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis preditoras (ou independentes ou, features)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável dependente, ou target, ou label (ah, vcs entenderam :)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devolve uma tupla com 4 elementos: X de treino, X de teste, y de treino, y de teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, # preditoras \n",
    "                                                        y, # target\n",
    "                                                        test_size=.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "# Vamos ver quantas linhas ficamos com treino e teste\n",
    "X_treino.shape, X_teste.shape, y_treino.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino.shape[0] / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnull busca quem é nulo (dados faltantes)\n",
    "X_treino.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando modelos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o estimador, algoritmo, modelo, preditor, classificador (virge, que tanto de nome!)\n",
    "# Vamos alterar o número de iterações para cálculo da regressão logística, pois no default ele enche de warnings\n",
    "# que pode não ter chegado na melhor solução\n",
    "regressao_logistica = LogisticRegression(max_iter=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(regressao_logistica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos treinar utilizando cross validation\n",
    "valores_accuracy_rl = cross_val_score(estimator=regressao_logistica, \n",
    "                                  X=X_treino, \n",
    "                                  y=y_treino.values.flatten(), \n",
    "                                  cv=10, # 10-fold CV\n",
    "                                  scoring='accuracy') # teste com accuracy para verificar acurácia do modelo\n",
    "valores_accuracy_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valores_accuracy_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_accuracy_rl = valores_accuracy_rl.mean()\n",
    "f'accuracy: {media_accuracy_rl*100}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de bagging mais famoso!\n",
    "random_forest = RandomForestClassifier()\n",
    "# Vamos treinar utilizando cross validation (sempre!!)\n",
    "valores_accuracy_rf = cross_val_score(estimator=random_forest, \n",
    "                                      X=X_treino, \n",
    "                                      y=y_treino.values.flatten(), \n",
    "                                      cv=10, # \n",
    "                                  scoring= 'accuracy')\n",
    "valores_accuracy_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_accuracy_rf = valores_accuracy_rf.mean()\n",
    "f'accuracy: {media_accuracy_rf*100}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(random_state=42, \n",
    "                              objective='binary:logistic', \n",
    "                              use_label_encoder=False, \n",
    "                              eval_metric='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos treinar utilizando cross validation (sempre!!)\n",
    "valores_accuracy_xgb = cross_val_score(estimator=xgb_model, \n",
    "                                      X=X_treino, \n",
    "                                      y=y_treino.values.flatten(), \n",
    "                                      cv=10, # \n",
    "                                  scoring='accuracy')\n",
    "valores_accuracy_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_accuracy_xgb = valores_accuracy_xgb.mean()\n",
    "\n",
    "f'accuracy: {media_accuracy_xgb*100}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressao_logistica.fit(X_treino, y_treino.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressao_logistica.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeficientes = pd.DataFrame(regressao_logistica.coef_)\n",
    "df_coeficientes.columns=regressao_logistica.feature_names_in_\n",
    "df_coeficientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a> Finalmente </a>\n",
    "\n",
    "Agora que temos nosso modelo final, podemos fazer inferências dos valores de classificação no teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver estimadores scikit learn\n",
    "# estimador é treinado com fit\n",
    "# estimador prediz com predict\n",
    "predicoes_status = regressao_logistica.predict(X_teste)\n",
    "predicoes_status[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicoes_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes_vs_real = pd.DataFrame({'predicao': predicoes_status.flatten(), 'real': y_teste.values.flatten()})\n",
    "predicoes_vs_real.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true=y_teste, y_pred=predicoes_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_teste, y_pred=predicoes_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_numericas = X_treino.select_dtypes(exclude=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer([('num_cols', scaler, colunas_numericas)])\n",
    "\n",
    "pipe = Pipeline([(\"preprocessing\", transformer),\n",
    "                (\"classifier\", regressao_logistica)])\n",
    "\n",
    "pipe.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes = pipe.predict(X_teste)\n",
    "predicoes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste.values[:10].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_teste, predicoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando o modelo final para implantação\n",
    "# import pickle\n",
    "\n",
    "# pickle.dump(pipe, open('./models/pipe.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "568d49c0137d9ad5d2241477c92ffe9fa6c077cf6de8c1902ee986ea38b1f145"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
